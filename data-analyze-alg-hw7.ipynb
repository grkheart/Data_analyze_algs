{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание\n\n1. К алгоритму kNN, реализованному на уроке, реализовать добавление весов для соседей по любому из показанных на уроке принципов.\n2. *Написать функцию подсчета метрики качества кластеризации как среднее квадратичное внутрикластерное расстояние и построить график ее зависимости от количества кластеров k (взять от 1 до 10) для выборки данных из данного урока (создать датасет, как в методичке).","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import model_selection\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\nfrom matplotlib.colors import ListedColormap","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:54:33.894709Z","iopub.execute_input":"2022-08-10T09:54:33.895433Z","iopub.status.idle":"2022-08-10T09:54:34.853920Z","shell.execute_reply.started":"2022-08-10T09:54:33.895337Z","shell.execute_reply":"2022-08-10T09:54:34.852977Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"X, y = load_iris(return_X_y=True)\n\n# Для наглядности возьмем только первые два признака (всего в датасете их 4)\nX = X[:, :2]\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=1)\n\ncmap = ListedColormap(['red', 'green', 'blue'])\nplt.figure(figsize=(7, 7))\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:55:10.401198Z","iopub.execute_input":"2022-08-10T09:55:10.401617Z","iopub.status.idle":"2022-08-10T09:55:10.701079Z","shell.execute_reply.started":"2022-08-10T09:55:10.401578Z","shell.execute_reply":"2022-08-10T09:55:10.700196Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def e_metrics(x1, x2):\n    \n    distance = 0\n    for i in range(len(x1)):\n        distance += np.square(x1[i] - x2[i])\n        #distance += np.abs(x1[i] - x2[i])\n    \n    return np.sqrt(distance)\n    #return (distance)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:55:29.826943Z","iopub.execute_input":"2022-08-10T09:55:29.827526Z","iopub.status.idle":"2022-08-10T09:55:29.832991Z","shell.execute_reply.started":"2022-08-10T09:55:29.827489Z","shell.execute_reply":"2022-08-10T09:55:29.831720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def knn(x_train, y_train, x_test, k):\n    \n    answers = []\n    for x in x_test:\n        test_distances = []\n        #print(len(answers))    \n        for i in range(len(x_train)):\n            \n            # расчет расстояния от классифицируемого объекта до\n            # объекта обучающей выборки\n            distance = e_metrics(x, x_train[i])\n            \n            # Записываем в список значение расстояния и ответа на объекте обучающей выборки\n            test_distances.append((distance, y_train[i]))\n        \n        # создаем словарь со всеми возможными классами\n        classes = {class_item: 0 for class_item in set(y_train)}\n        \n        # Сортируем список и среди первых k элементов подсчитаем частоту появления разных классов\n        for d in sorted(test_distances)[0:k]:\n            classes[d[1]] += 1\n            \n        # Записываем в список ответов наиболее часто встречающийся класс\n        answers.append(sorted(classes, key=classes.get)[-1])\n    return answers","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:55:40.310716Z","iopub.execute_input":"2022-08-10T09:55:40.311422Z","iopub.status.idle":"2022-08-10T09:55:40.320680Z","shell.execute_reply.started":"2022-08-10T09:55:40.311387Z","shell.execute_reply":"2022-08-10T09:55:40.319574Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def accuracy(pred, y):\n    return (sum(pred == y) / len(y))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:55:50.749915Z","iopub.execute_input":"2022-08-10T09:55:50.750901Z","iopub.status.idle":"2022-08-10T09:55:50.760208Z","shell.execute_reply.started":"2022-08-10T09:55:50.750837Z","shell.execute_reply":"2022-08-10T09:55:50.759217Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"k = 28\n\ny_pred = knn(X_train, y_train, X_test, k)\n\nprint(f'Точность алгоритма при k = {k}: {accuracy(y_pred, y_test):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:56:03.383008Z","iopub.execute_input":"2022-08-10T09:56:03.383708Z","iopub.status.idle":"2022-08-10T09:56:03.415932Z","shell.execute_reply.started":"2022-08-10T09:56:03.383671Z","shell.execute_reply":"2022-08-10T09:56:03.414927Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_graph(X_train, y_train, k):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n\n    h = .2\n\n    # Расчет пределов графика\n    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Получим предсказания для всех точек\n    Z = knn(X_train, y_train, np.c_[xx.ravel(), yy.ravel()], k)\n\n    # Построим график\n    Z = np.array(Z).reshape(xx.shape)\n    plt.figure(figsize=(7,7))\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Добавим на график обучающую выборку\n    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(f\"Трехклассовая kNN классификация при k = {k}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:56:46.218365Z","iopub.execute_input":"2022-08-10T09:56:46.219037Z","iopub.status.idle":"2022-08-10T09:56:46.228094Z","shell.execute_reply.started":"2022-08-10T09:56:46.219000Z","shell.execute_reply":"2022-08-10T09:56:46.227060Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:56:49.963786Z","iopub.execute_input":"2022-08-10T09:56:49.964455Z","iopub.status.idle":"2022-08-10T09:56:49.971878Z","shell.execute_reply.started":"2022-08-10T09:56:49.964423Z","shell.execute_reply":"2022-08-10T09:56:49.970786Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"get_graph(X_train, y_train, k)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:56:51.804580Z","iopub.execute_input":"2022-08-10T09:56:51.805176Z","iopub.status.idle":"2022-08-10T09:56:52.724587Z","shell.execute_reply.started":"2022-08-10T09:56:51.805106Z","shell.execute_reply":"2022-08-10T09:56:52.723670Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Задание 1**\n\nК алгоритму kNN, реализованному на уроке, реализовать добавление весов для соседей по любому из показанных на уроке принципов.","metadata":{}},{"cell_type":"code","source":"def get_weight(x1, x2, q):\n    \n    distance = 0\n    for i in range(len(x1)):\n        distance += np.square(x1[i] - x2[i])\n        #distance += np.abs(x1[i] - x2[i])\n    d = np.sqrt(distance)\n    w = q**d\n    return w\n    #return (distance)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:57:24.549550Z","iopub.execute_input":"2022-08-10T09:57:24.550296Z","iopub.status.idle":"2022-08-10T09:57:24.555605Z","shell.execute_reply.started":"2022-08-10T09:57:24.550261Z","shell.execute_reply":"2022-08-10T09:57:24.554687Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def knn_weight(x_train, y_train, x_test, k, q):\n    \n    answers = []\n    for x in x_test:\n        test_distances = []\n        #print(len(answers))    \n        for i in range(len(x_train)):\n            \n            # расчет расстояния от классифицируемого объекта до\n            # объекта обучающей выборки\n            weight = get_weight(x, x_train[i], q)\n            \n            # Записываем в список значение расстояния и ответа на объекте обучающей выборки\n            test_distances.append((weight, y_train[i]))\n        \n        # создаем словарь со всеми возможными классами\n        classes = {class_item: 0 for class_item in set(y_train)}\n        \n        # Сортируем список и среди первых k элементов подсчитаем частоту появления разных классов\n        for d in sorted(test_distances)[0:k]:\n            classes[d[1]] += 1\n            \n        # Записываем в список ответов наиболее часто встречающийся класс\n        answers.append(sorted(classes, key=classes.get)[0])\n    return answers","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:57:53.357134Z","iopub.execute_input":"2022-08-10T09:57:53.357507Z","iopub.status.idle":"2022-08-10T09:57:53.364964Z","shell.execute_reply.started":"2022-08-10T09:57:53.357474Z","shell.execute_reply":"2022-08-10T09:57:53.363986Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_graph_weight(X_train, y_train, k, q):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n\n    h = .2\n\n    # Расчет пределов графика\n    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Получим предсказания для всех точек\n    Z = knn_weight(X_train, y_train, np.c_[xx.ravel(), yy.ravel()], k, q)\n\n    # Построим график\n    Z = np.array(Z).reshape(xx.shape)\n    plt.figure(figsize=(7,7))\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Добавим на график обучающую выборку\n    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(f\"Трехклассовая kNN классификация при k = {k}, q={q}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:58:05.452383Z","iopub.execute_input":"2022-08-10T09:58:05.452775Z","iopub.status.idle":"2022-08-10T09:58:05.463707Z","shell.execute_reply.started":"2022-08-10T09:58:05.452742Z","shell.execute_reply":"2022-08-10T09:58:05.461716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"k = 1\nq = 0.111\ny_pred = knn_weight(X_train, y_train, X_test, k, q)\n\nprint(f'Точность алгоритма при k = {k}: {accuracy(y_pred, y_test):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:58:31.275910Z","iopub.execute_input":"2022-08-10T09:58:31.276287Z","iopub.status.idle":"2022-08-10T09:58:31.310106Z","shell.execute_reply.started":"2022-08-10T09:58:31.276255Z","shell.execute_reply":"2022-08-10T09:58:31.309075Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"get_graph_weight(X_train, y_train, k, q)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:58:40.907756Z","iopub.execute_input":"2022-08-10T09:58:40.908829Z","iopub.status.idle":"2022-08-10T09:58:41.577918Z","shell.execute_reply.started":"2022-08-10T09:58:40.908778Z","shell.execute_reply":"2022-08-10T09:58:41.577007Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"k = 15\nq = 0.111\ny_pred = knn_weight(X_train, y_train, X_test, k, q)\n\nprint(f'Точность алгоритма при k = {k}: {accuracy(y_pred, y_test):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:58:52.789390Z","iopub.execute_input":"2022-08-10T09:58:52.790349Z","iopub.status.idle":"2022-08-10T09:58:52.872236Z","shell.execute_reply.started":"2022-08-10T09:58:52.790307Z","shell.execute_reply":"2022-08-10T09:58:52.869118Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"get_graph_weight(X_train, y_train, k, q)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:59:00.837096Z","iopub.execute_input":"2022-08-10T09:59:00.837468Z","iopub.status.idle":"2022-08-10T09:59:01.509485Z","shell.execute_reply.started":"2022-08-10T09:59:00.837437Z","shell.execute_reply":"2022-08-10T09:59:01.508555Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"k = 28\nq = 0.111\ny_pred = knn_weight(X_train, y_train, X_test, k, q)\n\nprint(f'Точность алгоритма при k = {k}: {accuracy(y_pred, y_test):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:59:14.165463Z","iopub.execute_input":"2022-08-10T09:59:14.165860Z","iopub.status.idle":"2022-08-10T09:59:14.198668Z","shell.execute_reply.started":"2022-08-10T09:59:14.165826Z","shell.execute_reply":"2022-08-10T09:59:14.197649Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"get_graph_weight(X_train, y_train, k, q)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:59:24.520815Z","iopub.execute_input":"2022-08-10T09:59:24.521251Z","iopub.status.idle":"2022-08-10T09:59:25.625508Z","shell.execute_reply.started":"2022-08-10T09:59:24.521211Z","shell.execute_reply":"2022-08-10T09:59:25.624671Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"k =28\nq = 0.333\ny_pred = knn_weight(X_train, y_train, X_test, k, q)\n\nprint(f'Точность алгоритма при k = {k}: {accuracy(y_pred, y_test):.3f}')from sklearn.datasets import make_blobs\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:59:41.292332Z","iopub.execute_input":"2022-08-10T09:59:41.292780Z","iopub.status.idle":"2022-08-10T09:59:41.327117Z","shell.execute_reply.started":"2022-08-10T09:59:41.292744Z","shell.execute_reply":"2022-08-10T09:59:41.326092Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"get_graph_weight(X_train, y_train, k, q)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T09:59:51.792267Z","iopub.execute_input":"2022-08-10T09:59:51.792624Z","iopub.status.idle":"2022-08-10T09:59:52.461447Z","shell.execute_reply.started":"2022-08-10T09:59:51.792592Z","shell.execute_reply":"2022-08-10T09:59:52.460527Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Задание 2**\n\n*Написать функцию подсчета метрики качества кластеризации как среднее квадратичное внутрикластерное расстояние и построить график ее зависимости от количества кластеров k (взять от 1 до 10) для выборки данных из данного урока (создать датасет, как в методичке).","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_blobs\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:00:38.641432Z","iopub.execute_input":"2022-08-10T10:00:38.641811Z","iopub.status.idle":"2022-08-10T10:00:38.646921Z","shell.execute_reply.started":"2022-08-10T10:00:38.641779Z","shell.execute_reply":"2022-08-10T10:00:38.645877Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X, y = make_blobs(n_samples=800, centers = 3, random_state=1)\nX[:,1] *= 1","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:00:47.502000Z","iopub.execute_input":"2022-08-10T10:00:47.503015Z","iopub.status.idle":"2022-08-10T10:00:47.509792Z","shell.execute_reply.started":"2022-08-10T10:00:47.502968Z","shell.execute_reply":"2022-08-10T10:00:47.508936Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nplt.scatter(X[:, 0], X[:, 1])","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:00:57.106693Z","iopub.execute_input":"2022-08-10T10:00:57.107732Z","iopub.status.idle":"2022-08-10T10:00:57.325594Z","shell.execute_reply.started":"2022-08-10T10:00:57.107689Z","shell.execute_reply":"2022-08-10T10:00:57.324682Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def mean_quadratic_intracluster(centroids, clusters):\n    k=0\n    quality=0\n    for c in centroids:\n        for x in clusters[k]:\n            quality += e_metrics(x, c)**2\n        k+=1\n    return quality / k","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:01:09.941845Z","iopub.execute_input":"2022-08-10T10:01:09.942250Z","iopub.status.idle":"2022-08-10T10:01:09.950658Z","shell.execute_reply.started":"2022-08-10T10:01:09.942214Z","shell.execute_reply":"2022-08-10T10:01:09.949608Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def kmeans(data, k, max_iterations, min_distance):    \n    # инициализируем центроиды как первые k элементов датасета\n    centroids = [data[i] for i in range(k)]\n    \n    for _ in range(max_iterations):\n        # Создадим словарь для классификации\n        classes = {i: [] for i in range(k)}\n        \n        # классифицируем объекты по центроидам\n        for x in data:\n            # определим расстояния от объекта до каждого центроида\n            distances = [e_metrics(x, centroid) for centroid in centroids]\n            # отнесем объект к кластеру, до центроида которого наименьшее расстояние\n            classification = distances.index(min(distances))\n            classes[classification].append(x)\n        \n        # сохраним предыдущие центроиды в отдельный список для последующего сравнения сновыми\n        old_centroids = centroids.copy()\n        \n        # пересчитаем центроиды как среднее по кластерам\n        for classification in classes:\n            centroids[classification] = np.average(classes[classification], axis=0)\n            \n        # сравним величину смещения центроидов с минимальной\n        optimal = True\n        for centroid in range(len(centroids)):\n            if np.sum(abs((centroids[centroid] - old_centroids[centroid]) / old_centroids * 100)) > min_distance:\n                optimal = False\n                \n        # если все смещения меньше минимального, останавливаем алгоритм  \n        if optimal:\n            break\n    \n    return old_centroids, classes","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:01:21.182465Z","iopub.execute_input":"2022-08-10T10:01:21.183442Z","iopub.status.idle":"2022-08-10T10:01:21.193705Z","shell.execute_reply.started":"2022-08-10T10:01:21.183404Z","shell.execute_reply":"2022-08-10T10:01:21.192646Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def kmeans_predict(centroids, data):    \n    # инициализируем центроиды как первые k элементов датасета\n    classes = [i for i in range(len(centroids))]\n    label = []\n    # классифицируем объекты по центроидам\n    for x in data:\n            # определим расстояния от объекта до каждого центроида\n            distances = [e_metrics(x, centroid) for centroid in centroids]\n            # отнесем объект к кластеру, до центроида которого наименьшее расстояние\n            classification = distances.index(min(distances))\n            #print(classification)\n            label.append(classification)\n    return label","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:01:32.806999Z","iopub.execute_input":"2022-08-10T10:01:32.807366Z","iopub.status.idle":"2022-08-10T10:01:32.816628Z","shell.execute_reply.started":"2022-08-10T10:01:32.807337Z","shell.execute_reply":"2022-08-10T10:01:32.815445Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def visualize(centroids, classes):\n    colors = ['r', 'g', 'b','m','y']\n    \n    plt.figure(figsize=(7,7))\n    \n    # нанесем на график центроиды\n    for centroid in centroids:\n        plt.scatter(centroid[0], centroid[1], marker='x', s=130, c='black')\n        \n    # нанесем объекты раскрашенные по классам\n    for class_item in classes:\n        for x in classes[class_item]:\n            plt.scatter(x[0], x[1], color=colors[class_item])\n    plt.grid(True)        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:01:42.528783Z","iopub.execute_input":"2022-08-10T10:01:42.529150Z","iopub.status.idle":"2022-08-10T10:01:42.538464Z","shell.execute_reply.started":"2022-08-10T10:01:42.529114Z","shell.execute_reply":"2022-08-10T10:01:42.537585Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"max_iterations = 5\nmin_distance = 1e-4\nk=3\ncentroids, clusters = kmeans(X[10:], k, max_iterations, min_distance)\n\nvisualize(centroids, clusters)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:01:52.881314Z","iopub.execute_input":"2022-08-10T10:01:52.881692Z","iopub.status.idle":"2022-08-10T10:01:59.701504Z","shell.execute_reply.started":"2022-08-10T10:01:52.881655Z","shell.execute_reply":"2022-08-10T10:01:59.700602Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"result = mean_quadratic_intracluster(centroids, clusters)\nprint(f'среденее квадратичное внутриклассовое : {result}' )","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:02:10.322598Z","iopub.execute_input":"2022-08-10T10:02:10.323312Z","iopub.status.idle":"2022-08-10T10:02:10.338283Z","shell.execute_reply.started":"2022-08-10T10:02:10.323276Z","shell.execute_reply":"2022-08-10T10:02:10.337291Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"mean_quadratic_list = []\nfor k in range(1, 11):\n    centroids, clusters = kmeans(X[10:], k, max_iterations, min_distance)\n    result = mean_quadratic_intracluster(centroids, clusters)\n    mean_quadratic_list.append(result)\n    print(f'среденее квадратичное внутриклассовое : {result} при k = {k}' )","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:02:20.772346Z","iopub.execute_input":"2022-08-10T10:02:20.773252Z","iopub.status.idle":"2022-08-10T10:02:22.857765Z","shell.execute_reply.started":"2022-08-10T10:02:20.773213Z","shell.execute_reply":"2022-08-10T10:02:22.856872Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"k=np.arange(10)\nplt.xlabel('number of clusters')\nplt.xticks(k+1)\nplt.ylabel('cluster cohesion')\nplt.plot(k+1, mean_quadratic_list)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:02:31.110842Z","iopub.execute_input":"2022-08-10T10:02:31.111979Z","iopub.status.idle":"2022-08-10T10:02:31.304486Z","shell.execute_reply.started":"2022-08-10T10:02:31.111931Z","shell.execute_reply":"2022-08-10T10:02:31.303561Z"},"trusted":true},"execution_count":34,"outputs":[]}]}